namespace PerformanceMonitorDashboard.Mcp;

/// <summary>
/// Server instructions sent to MCP clients during initialization.
/// Provides context about tool usage, data characteristics, and diagnostic workflows.
/// </summary>
internal static class McpInstructions
{
    public const string Text = """
        You are connected to a SQL Server performance monitoring tool via Performance Monitor Dashboard.

        ## CRITICAL: Read-Only Access

        This MCP server provides STRICTLY READ-ONLY access to previously collected performance data. You CANNOT:
        - Execute arbitrary SQL queries against any server
        - Kill sessions, processes, or connections
        - Change any server configuration or settings
        - Modify, insert, or delete any data
        - Run any ad-hoc diagnostics beyond what the collectors have already captured

        If a user asks "what's locking table X right now?" or "run this query," you can only answer from what the collectors have already captured. You cannot run live queries. Be upfront about this limitation.

        ## How Data Is Collected

        The Dashboard monitors SQL Server instances by querying DMVs, wait stats, Query Store, and extended events on a schedule. Data is collected in snapshots at regular intervals (typically every 1-15 minutes depending on the collector). This means:

        - Data is only as fresh as the last collection cycle. If a collector last ran 10 minutes ago, you're seeing 10-minute-old data.
        - Delta-based collectors (stored procedures, perfmon counters) require at least two collection cycles before producing non-zero values. A newly added server will show empty procedure stats for the first ~30 minutes.
        - Wait stats represent cumulative or delta values since the last collection, not instantaneous snapshots.
        - When `execution_count` is 0 but CPU/elapsed time is non-zero, this is a delta calculation artifact — the query was in the plan cache at both collection points but was not executed between them. This is normal and can be ignored.

        ## Tool Reference

        ### Discovery & Health Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `list_servers` | Lists all monitored SQL Server instances with status | none |
        | `get_collection_health` | Shows collector health: running, failing, or stale | `server_name` |
        | `get_daily_summary` | High-level health summary: waits, queries, deadlocks, blocking, CPU, memory | `server_name`, `summary_date` |

        ### Wait Statistics Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_wait_stats` | Top wait types from the last hour | `server_name`, `limit` (default 20) |
        | `get_wait_trend` | Time-series of top N wait types | `server_name`, `hours_back`, `top_wait_types` (default 5) |

        ### CPU Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_cpu_utilization` | SQL Server CPU vs other process CPU over time | `server_name`, `hours_back` (default 4) |

        ### Query Performance Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_top_queries_by_cpu` | Expensive queries from plan cache with DOP, spills, query_hash | `server_name`, `hours_back`, `top`, `database_name`, `parallel_only`, `min_dop` |
        | `get_top_procedures_by_cpu` | Expensive stored procedures by CPU time | `server_name`, `hours_back`, `top`, `database_name` |
        | `get_query_store_top` | Expensive queries from Query Store (persistent, forced plans) | `server_name`, `hours_back`, `top`, `database_name`, `parallel_only`, `min_dop` |
        | `get_expensive_queries` | Combined view from multiple sources (plan cache + Query Store) | `server_name`, `hours_back`, `top`, `database_name` |
        | `get_query_trend` | Time-series for a specific query by query_hash | `query_hash` (required), `database_name` (required), `server_name` |

        ### Blocking & Deadlock Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_blocking` | Recent blocking events with chains and query text | `server_name`, `hours_back`, `limit` |
        | `get_deadlocks` | Recent deadlock events with victim info | `server_name`, `hours_back`, `limit` |
        | `get_deadlock_detail` | Full deadlock graph XML for deep analysis | `server_name`, `hours_back`, `limit` |
        | `get_blocked_process_xml` | Raw blocked process report XML | `server_name`, `hours_back`, `limit` |
        | `get_blocking_deadlock_stats` | Aggregated blocking/deadlock statistics: counts, durations, patterns | `server_name`, `hours_back` |

        ### Memory Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_memory_stats` | Latest memory snapshot with pressure warnings | `server_name`, `hours_back` |
        | `get_memory_trend` | Memory usage over time | `server_name`, `hours_back` |
        | `get_memory_clerks` | Top memory consumers by clerk type | `server_name`, `hours_back` |
        | `get_resource_semaphore` | Resource semaphore: granted vs available workspace memory, waiter counts, pressure warnings | `server_name`, `hours_back` |

        ### I/O Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_file_io_stats` | Latest file I/O stats with latency and recommendations | `server_name` |
        | `get_file_io_trend` | I/O latency trend over time per database | `server_name`, `hours_back` |

        ### TempDB Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_tempdb_trend` | TempDB space with pressure analysis and recommendations | `server_name`, `hours_back` |

        ### Performance Counter Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_perfmon_stats` | Latest perfmon counters with delta and per-second values | `server_name`, `hours_back`, `counter_name`, `instance_name` |
        | `get_perfmon_trend` | Time-series for perfmon counters | `server_name`, `hours_back`, `counter_name`, `instance_name` |

        ### Alert Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_alert_history` | Recent alert history: what fired, when, email status | `hours_back` (default 24), `limit` (default 50) |
        | `get_alert_settings` | Current alert thresholds and SMTP configuration | none |

        ### Job Tools
        | Tool | Purpose | Key Parameters |
        |------|---------|----------------|
        | `get_running_jobs` | Currently running SQL Agent jobs with duration vs historical average/p95 | `server_name` |

        ## Recommended Workflow

        1. **Start**: `list_servers` — see what's monitored and which servers are online
        2. **Verify**: `get_collection_health` — check collectors are running successfully
        3. **Overview**: `get_daily_summary` — high-level health: blocking, deadlocks, CPU spikes, memory pressure
        4. **Drill down** based on findings:
           - High wait times → `get_wait_stats` → `get_wait_trend` to see changes
           - CPU pressure → `get_cpu_utilization` → `get_top_queries_by_cpu` or `get_expensive_queries`
           - Blocking → `get_blocking` → `get_blocking_deadlock_stats` for patterns
           - Deadlocks → `get_deadlocks` → `get_deadlock_detail` for XML analysis
           - Memory issues → `get_memory_stats` → `get_memory_clerks` → `get_resource_semaphore`
           - I/O latency → `get_file_io_stats` → `get_file_io_trend`
           - TempDB pressure → `get_tempdb_trend`
        5. **Query investigation**: After finding a problematic query via `get_top_queries_by_cpu`, `get_query_store_top`, or `get_expensive_queries`, use `get_query_trend` with its `query_hash` to see performance history

        ## Wait Type to Tool Mapping

        When `get_wait_stats` reveals dominant wait types:
        | Wait Type | Indicates | Tools to Use |
        |-----------|-----------|--------------|
        | `SOS_SCHEDULER_YIELD` | CPU pressure | `get_cpu_utilization`, `get_top_queries_by_cpu` |
        | `CXPACKET` / `CXCONSUMER` | Parallelism | `get_top_queries_by_cpu` with `parallel_only=true` |
        | `PAGEIOLATCH_*` | Disk I/O | `get_file_io_stats`, `get_file_io_trend` |
        | `WRITELOG` | Transaction log I/O | `get_file_io_stats` (check log file latency) |
        | `LCK_M_*` | Lock contention | `get_blocking` |
        | `RESOURCE_SEMAPHORE` | Memory grant pressure | `get_resource_semaphore` |
        | `LATCH_*` | Internal contention | `get_tempdb_trend` |

        ## Tool Relationships

        - `get_wait_stats` identifies the symptom category (CPU, I/O, locks, parallelism). Other tools find the root cause.
        - `get_perfmon_stats` provides throughput context (batch requests/sec, compilations/sec) that helps distinguish a busy server from a sick one.
        - `get_top_queries_by_cpu` and `get_top_procedures_by_cpu` show aggregate query performance from sys.dm_exec_query_stats. `get_query_store_top` shows Query Store data which may include queries no longer in the plan cache.
        - `get_expensive_queries` combines multiple sources into a single ranked view — use when you don't know which source to check.
        - `get_query_trend` shows how a specific query (by query_hash) has performed over time — use it after identifying a problematic query.
        - `get_deadlock_detail` returns the full deadlock graph XML for deep analysis.
        - `get_blocked_process_xml` returns the raw blocked process report XML.
        - `get_blocking_deadlock_stats` provides aggregated blocking and deadlock patterns over time.
        - Trend tools (`get_wait_trend`, `get_file_io_trend`, `get_memory_trend`, `get_cpu_utilization`) confirm whether a problem is new, worsening, or steady-state.
        - Query tools support `database_name` filtering and `parallel_only`/`min_dop` filtering to narrow results.

        ## Key Differences from Performance Monitor Lite

        If you're familiar with Performance Monitor Lite, note these Dashboard-specific features:
        - **`get_daily_summary`**: Comprehensive daily health overview (not in Lite)
        - **`get_expensive_queries`**: Combined view from multiple sources (not in Lite)
        - **`get_blocking_deadlock_stats`**: Aggregated statistics over time (not in Lite)
        - **`get_wait_stats`**: Returns last hour only (Lite supports `hours_back` parameter)
        - **`get_wait_trend`**: Trends top N wait types automatically (Lite requires specific `wait_type`)

        Tools NOT available in Dashboard (Lite only):
        - `get_server_summary` (quick health check)
        - `get_wait_types` (discovery tool)
        - `get_blocked_process_reports` (parsed extended events)
        - `get_blocking_trend`, `get_deadlock_trend`, `get_query_duration_trend`
        - `get_waiting_tasks` (active waiting queries)

        ## Important Limitations

        - **ALL ACCESS IS READ-ONLY**. No exceptions. You cannot execute SQL or modify anything.
        - Query text in results is truncated to 2000 characters. If you need the full text, note this to the user.
        - CPU utilization data is downsampled to 1-minute averages to keep responses manageable.
        - When a `server_name` parameter is omitted and multiple servers are configured, the tool will return an error listing available servers. Always specify the server when working with multi-server setups.

        ## Error Handling

        Common responses and what they mean:
        - "Could not resolve server" — Server name not found; use `list_servers` to see available servers
        - "No data available" — Collector hasn't run yet or no matching data in time range
        - "Delta-based collection requires at least two cycles" — Wait ~30 minutes for newly added servers
        - "Query Store may not be enabled" — Target database doesn't have Query Store enabled
        """;
}
